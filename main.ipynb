{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "raI2_VQLKhvE"
   },
   "source": [
    "### AC109B Final Project\n",
    "TEAM 37: Ellie Jungmin Han, Timothy Lee, Chih-Kang Chang, Dabin Choe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Annual Radiation Intensities on Buildings using 3D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  The use of artificial intelligence and machine learning are increasing in prominence in the building, architecture and construction sectors (Kalogirou, 2000). One area that is ideally suited to take advantage of these powerful new technologies is building energy simulation and environmental analysis (Goldstein & Coco, 2015). \n",
    "\n",
    "  For the estimation of the energy flow and the annual radiation intensities on buildings, physics-based models are often used. The algorithms employed are fairly complicated, involving the solution of complex differential equations. The software for this simulation usually requires high computational power and a considerable amount of time to output accurate predictions. Therefore, data-driven models for predicting physical properties on buildings are becoming increasingly popular. Artificial Neural Network (ANN) analysis based on prefabricated or simulated data of environmental systems and is therefore likely to be better and appropriate for designers than other methods. \n",
    "\n",
    "There are increasing attention and publications in machine learning research predicting surface solar radiation (Yadav & Chandel (2014), Mohandes, Rehman, & Halawani (1998), Voyant et al., (2017)) and building energy prediction (Amasyali & El-Gohary, (2018), Goldstein & Coco, (2018)). ANN models may be used to provide innovative ways of solving design problems which allow designers to get instantaneous feedback on the effect of a proposed change in building design. \n",
    "\n",
    "**The objective of this project is to introduce deep learning methods to represent physical properties on buildings (annual radiation intensity and exposure) without learning physics-based models.** This will show the future capacity of integrated ANNs as a tool in building performance simulation and modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Review of BPS problems*\n",
    "\n",
    "  Building performance simulation (BPS) program is a powerful tool that can be used to evaluate the energy performance and environmental impacts of buildings throughout their lifecycle. Environmental analysis (EA) and building geometry modeling (BGM), which form a major part of BPS, help designers make responsive and environmentally conscious designs in the early modeling stage (Radford and Gero, 1987). Environmental analysis includes PV calculator, daylight simulator, and weather analysis platforms while building surface modelings include parametric geometry calculations.\n",
    " \n",
    "  Since both EA and BGM are required for an efficient calculation of BPS, many researchers attempted to develop an end-to-end model that removes separate steps. Kikegawa et al. (2003) worked on a simplified physics-based heat transfer algorithms that were integrated into urban canopy models to account for interactions between buildings and their surrounding environment. Umi, a Rhinoceros-based urban energy-modeling tool that allows users to carry out energy, daylighting, and walkability assessment of the neighborhood is another coupling model (Reinhart et al. 2013). However, many of such models are either computationally inefficient or limited in the areas explored due to the complexity of physics simulation, and an alternative surrogate model is needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Review of related problems*\n",
    "\n",
    "  The neural network, especially Deep Learning has gained prominence as a prediction model that could replace a physics model. Many researchers including Singaravel et al, (2018) explored the potential application of Long-Short-Term-Memory (LSTM) architecture in monthly energy consumption prediction and the use of Transfer Learning to greatly reduce the complexity of learning a model. However, to the best of our knowledge, not much deep learning applied research has been done in the field of BPS.\n",
    "\t\n",
    "  In a review done by Niu et al. (2017),  various data-driven predictive models were compared and assessed based on their ability to accurately forecast solar irradiation using hourly weather data. Among the models that were tested, which included Artificial Neural Network (ANN), Support Vector Machine (SVM), State Space (SS) and a Bayesian Network (BM). It was found that the most successful model was the RNN model, which had the greatest prediction accuracy, over the prediction period, which spanned a total of 3 months. However, this particular study utilized a small set of input variables and also found that a decreased sampling rate resulted in decreased performance of the model, although computational speed was increased. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Review of 3D problem*\n",
    "\t\n",
    "  RNNs have been proven to excel at modelling sequential data, by giving them access to to previous context and time-dependencies in data. However, a current limitation of the RNN structure is the fact that the input is explicitly required to be single-dimensional, which requires any multi-dimensional data to be pre-processed and flattened before being fed into the RNN model architecture.] CNNs are an example of NN that are able to use multidimensional data (for images). However, CNNs lose the ability to learn from long-term memory, as well as the large increase in computational cost as the input data increases due to the multi-dimensionality. This holds true In general, by increasing the dimensionality of data/architecture of NN models, the computational time increases greatly, due to the multitude of layers and parameters involved in the tuning of such architectures. \n",
    "\n",
    "  One proposed method in literature to extend the functionality of RNNs to multi-dimensional data is discussed by Graves et al, (2007). The proposed method extends the dimensionality of the data input into the RNN architecture, while avoiding the extreme scaling issues experienced by CNNs. The Multi-Dimensional Recurrent Neural Network (MDNN)  involves altering the architecture of the  RNN to expand the number of recurrent connections and forget gates such that there is one for each dimension. This may be an interesting architecture to look into for our specific problem, which is multidimensional - both spatially and temporally (3-dimensional buildings, with values changing over time).\n",
    "\n",
    "  Another possible approach for our specific problem involving surfaces of various buildings, and the prediction of radiation values, one possible approach is to slice the 3-dimensional building representation into 2-dimensional segments (similar to the CT scan discussed below), and feed each 2-dimensional slice into a CNN. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Research with a similar data structure\n",
    "\n",
    "  Though there are not many studies applying deep learning in the field of BPS, there are other studies that have a similar data structure that could be a good reference for our model.\n",
    "\n",
    "  One study is the analysis of MRI images, for example, “3D Convolutional Neural Networks for Tumor Segmentation using Long-range 2D Context“ (Mlynarski et al., 2018). MRI is a scanning technology that can generate images of slices of the imaging target. With 2D images stacking as a pile, it is actually 3D information. However, segmentation of tumors in large medical images is still a very challenging task. One of the main drawbacks of CNNs is their computational cost resulting from applications of thousands of costly operations (convolutions, poolings, upsampling) on input images. This aspect is particularly problematic for segmentation problems in large medical images such as MRI or CT scans. The authors proposed a neural network that can perform tumor segmentation based on the 2D-3D images. The model extracts features by 2D CNNs from a long-range 2D context in three orthogonal directions, and the features are used as an additional input to a 3D CNN. Such design considerably increases the size of the receptive field compared to standard 3D models taking as input only the raw intensities of voxels of a subvolume.\n",
    "\n",
    "  Another study that may be a great reference is the analysis of point cloud data in the field of Robotics, for example, “VoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition” (Maturana et al., 2015). Point cloud data is a set of point with coordinates in 3D space, measured by LiDAR or RGBD camera. The authors proposed the VoxNet, a basic 3D CNN architecture that can be applied to create fast and accurate object class detectors for 3D point cloud data. VoxNet is composed of an input layer, two 3D convolutional layers, a maxpool layer, a fully connected network, and the output layer. In order to cover objects of different scales, e.g. a truck or a traffic sign, a multiresolution VoxNet can be achieved by combining two networks with an identical VoxNet architectures, each receiving occupancy grids at different resolutions, and fuse the information from both networks by concatenating the outputs of their respective FC(128) layers. With other preprocessing and training techniques, VoxNet achieves a surprisingly good result with such a simple structure. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  For our proposed problem, there is some similarity in our data representation to the 3D data structure of the studies mentioned above. However, the nature of our problem, deep learning methods to represent physical properties on buildings (annual radiation intensity and exposure), is quite different from those. In the problem, a tall building may have a significant effect (causing low radiation) on the low building in its shadow depending on the direction of sunlight, and the voxel of these two building may be far away in the spatial relationship. The best structure to embed spatial information is the convolution layers, and we may need a deep network to embed information that covers a wide range as described. However, 3D convolution is computationally costly, and a deep network may not be applicable. In addition, the objective of the above-mentioned research with a similar data structure is categorical, while the output of our model will be numerical (radiation), which may be more difficult in some sense. These challenges may be overcome by applying techniques in the literature to interpret large spatial information wisely. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/Figures.png\" height=\"700\" width=\"1000\" />\n",
    "We used 3D architectural modeling tool, Rhinoceros and Grasshopper, and the radiation simulation tool, DIVA for Rhino. As for the data generation, we utilized both modeling and simulation tools to collect surface radiation values throughout a year. Total 2,170 datasets were collected including height variations of multiple target buildings, volume variations of a single building, and the orientation variation of a single building. We initially collected monthly and annual average exposure in surface radiation on buildings, but utilize annual values for the 3D CNN modeling. The figure above shows the location of the 5 different boundary buildings and the varied options of the target buildings with a result of simulations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IrCAUQ6nKhvF"
   },
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import clear_output\n",
    "import scipy.io\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATLAB Preprocessing Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    "html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}\n",
    "\n",
    "html { min-height:100%; margin-bottom:1px; }\n",
    "html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }\n",
    "html body td { vertical-align:top; text-align:left; }\n",
    "\n",
    "h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }\n",
    "h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }\n",
    "h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }\n",
    "\n",
    "a { color:#005fce; text-decoration:none; }\n",
    "a:hover { color:#005fce; text-decoration:underline; }\n",
    "a:visited { color:#004aa0; text-decoration:none; }\n",
    "\n",
    "p { padding:0px; margin:0px 0px 20px; }\n",
    "img { padding:0px; margin:0px 0px 20px; border:none; }\n",
    "p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } \n",
    "\n",
    "ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }\n",
    "ul li { padding:0px; margin:0px 0px 7px 0px; }\n",
    "ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }\n",
    "ul li ol li { list-style:decimal; }\n",
    "ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }\n",
    "ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }\n",
    "ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }\n",
    "ol li ol li { list-style-type:lower-alpha; }\n",
    "ol li ul { padding-top:7px; }\n",
    "ol li ul li { list-style:square; }\n",
    "\n",
    ".content { font-size:1.2em; line-height:140%; padding: 20px; }\n",
    "\n",
    "pre, code { font-size:12px; }\n",
    "tt { font-size: 1.2em; }\n",
    "pre { margin:0px 0px 20px; }\n",
    "pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }\n",
    "pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }\n",
    "pre.error { color:red; }\n",
    "\n",
    "@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }\n",
    "\n",
    "span.keyword { color:#0000FF }\n",
    "span.comment { color:#228B22 }\n",
    "span.string { color:#A020F0 }\n",
    "span.untermstring { color:#B20000 }\n",
    "span.syscmd { color:#B28C00 }\n",
    "\n",
    ".footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }\n",
    ".footer p { margin:0px; }\n",
    ".footer a { color:#878787; }\n",
    ".footer a:hover { color:#878787; text-decoration:underline; }\n",
    ".footer a:visited { color:#878787; }\n",
    "\n",
    "table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }\n",
    "table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }\n",
    "</style>\n",
    "  \n",
    "<body><div class=\"content\"><h2>Contents</h2><div><ul><li><a href=\"#1\">Clear Workspace and Load Data</a></li><li><a href=\"#2\">Loop through all target input txt files to be pre-processed</a></li><li><a href=\"#4\">Identify Building Edges</a></li><li><a href=\"#5\">Map Coordinates to Indices (in 3d matrix)</a></li><li><a href=\"#6\">Populate X and y pre-processed matrix</a></li><li><a href=\"#7\">Plot Output</a></li><li><a href=\"#8\">Save .mat file - Export X and y preprocessed data</a></li></ul></div><h2 id=\"1\">Clear Workspace and Load Data</h2><pre class=\"codeinput\">clear <span class=\"string\">all</span>; clc;\n",
    "txt_list = dir(<span class=\"string\">'test_buildings/with_boundary/*.txt'</span>); <span class=\"comment\">% reading all the images one by one .</span>\n",
    "\n",
    "<span class=\"comment\">%Check if data includes boundary buildings or not</span>\n",
    "include_boundary = 0;\n",
    "\n",
    "<span class=\"keyword\">if</span> include_boundary\n",
    "    b_mat = load(<span class=\"string\">'preprocessed_output_boundary/combined_boundary.mat'</span>);\n",
    "    boundaries = b_mat.boundary_building_mat;\n",
    "<span class=\"keyword\">else</span>\n",
    "    boundaries = zeros(51,51,51);\n",
    "<span class=\"keyword\">end</span>\n",
    "\n",
    "<span class=\"comment\">% Keep track of number of skipped files (either corruption errors or due to</span>\n",
    "<span class=\"comment\">% machine precision error when making grid assumptions</span>\n",
    "length(txt_list)\n",
    "skipped_files = {};\n",
    "skipped_file_count = 0;\n",
    "corrupted_files = {};\n",
    "corrupted_file_count = 0;\n",
    "</pre><h2 id=\"2\">Loop through all target input txt files to be pre-processed</h2><pre class=\"codeinput\"><span class=\"keyword\">for</span> i = 1:length(txt_list)\n",
    "</pre><pre class=\"codeinput\">clearvars <span class=\"string\">-except</span> <span class=\"string\">txt_list</span> <span class=\"string\">i</span> <span class=\"string\">skipped_file_count</span> <span class=\"string\">skipped_files</span> <span class=\"string\">corrupted_files</span> <span class=\"string\">corrupted_file_count</span> <span class=\"string\">boundaries</span> <span class=\"string\">include_boundary</span>\n",
    "filename = txt_list(i).name;\n",
    "folder = txt_list(i).folder;\n",
    "fid = fopen([folder <span class=\"string\">'/'</span> filename]);\n",
    "C = textscan(fid,<span class=\"string\">'%f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f'</span>,<span class=\"string\">'HeaderLines'</span>,1,<span class=\"string\">'delimiter'</span>,<span class=\"string\">','</span>);\n",
    "fclose(fid);\n",
    "f = {<span class=\"string\">'x'</span>,<span class=\"string\">'y'</span>,<span class=\"string\">'z'</span>, <span class=\"string\">'jan'</span>,<span class=\"string\">'feb'</span>,<span class=\"string\">'march'</span>, <span class=\"string\">'apr'</span>, <span class=\"string\">'may'</span>, <span class=\"string\">'june'</span> ,<span class=\"string\">'july'</span> ,<span class=\"string\">'aug'</span>, <span class=\"string\">'sept'</span> ,<span class=\"string\">'oct'</span> ,<span class=\"string\">'nov'</span>, <span class=\"string\">'dec'</span>, <span class=\"string\">'rad'</span>};\n",
    "b = cell2struct(C,f,  2);\n",
    "\n",
    "\n",
    "<span class=\"comment\">%read file</span>\n",
    "\n",
    "<span class=\"comment\">%Check if all columns have the same number of rows</span>\n",
    "num_rows  = length(b.x);\n",
    "<span class=\"keyword\">if</span> length(b.rad)&lt; num_rows\n",
    "    disp(<span class=\"string\">'file corrupted'</span>)\n",
    "    corrupted_file_count = corrupted_file_count + 1;\n",
    "    corrupted_files = {corrupted_files filename};\n",
    "    <span class=\"keyword\">continue</span>\n",
    "<span class=\"keyword\">end</span>\n",
    "\n",
    "\n",
    "\n",
    "building = [b.x b.y b.z b.rad];\n",
    "<span class=\"comment\">% unpack data</span>\n",
    "X = b.x;\n",
    "Y = b.y;\n",
    "Z = b.z;\n",
    "</pre><h2 id=\"4\">Identify Building Edges</h2><pre class=\"codeinput\"><span class=\"comment\">%Check data membership (shift all coordinates forward along an axis by 0.5</span>\n",
    "<span class=\"comment\">%(half increment) and back by 1 unit. If that coordinate exists in both</span>\n",
    "<span class=\"comment\">%shifted cases, then that point is not on the edge of the building.</span>\n",
    "<span class=\"comment\">%However if the point is excluded in one of the shifts, then it is an edge</span>\n",
    "<span class=\"comment\">%of a building and must be adjusted.</span>\n",
    "<span class=\"comment\">%</span>\n",
    "<span class=\"comment\">%Do this for all X/Y/Z and in both configurations - (+0.5, -1) and (-0.5, +1)</span>\n",
    "<span class=\"comment\">%Doing this will find all leading and ending edges.</span>\n",
    "\n",
    "\n",
    "<span class=\"comment\">%Check X</span>\n",
    "x_minus_half = ismember(X-0.5, X);\n",
    "x_plus_inc  = ismember(X+1,X);\n",
    "\n",
    "x_plus_half = ismember(X+0.5,X);\n",
    "x_minus_inc = ismember(X-1,X);\n",
    "\n",
    "lead_idx_X = find(x_plus_half &amp; not(x_minus_inc));\n",
    "end_idx_X = find(x_minus_half &amp; not(x_plus_inc));\n",
    "\n",
    "\n",
    "<span class=\"comment\">%Check Y</span>\n",
    "y_minus_half = ismember(Y-0.5, Y);\n",
    "y_plus_inc  = ismember(Y+1,Y);\n",
    "\n",
    "y_plus_half = ismember(Y+0.5,Y);\n",
    "y_minus_inc = ismember(Y-1,Y);\n",
    "\n",
    "lead_idx_Y_gen = find(y_plus_half &amp; not(y_minus_inc));\n",
    "end_idx_Y_gen = find(y_minus_half &amp; not(y_plus_inc));\n",
    "\n",
    "\n",
    "lead_idx_Y = lead_idx_Y_gen;\n",
    "end_idx_Y = end_idx_Y_gen;\n",
    "\n",
    "<span class=\"comment\">%Check Z</span>\n",
    "z_minus_half = ismember(Z-0.5, Z);\n",
    "z_plus_inc  = ismember(Z+1,Z);\n",
    "\n",
    "z_plus_half = ismember(Z+0.5,Z);\n",
    "z_minus_inc = ismember(Z-1,Z);\n",
    "\n",
    "lead_idx_Z = find(z_plus_half &amp; not(z_minus_inc));\n",
    "end_idx_Z = find(z_minus_half &amp; not(z_plus_inc));\n",
    "\n",
    "C_Z = intersect(lead_idx_Z,end_idx_Z);\n",
    "lead_idx_Z = setxor(lead_idx_Z,C_Z);\n",
    "\n",
    "\n",
    "<span class=\"comment\">% For intersections of 2 buildings, the method above fails because both</span>\n",
    "<span class=\"comment\">% shifts result in a single edge being identified as both a leading AND</span>\n",
    "<span class=\"comment\">% ending edge, so the correction for the edges do not work correctly.</span>\n",
    "<span class=\"comment\">% Therefore double edge cases must be identified and then the correct case</span>\n",
    "<span class=\"comment\">% must be used (either pushing in by +0.5 for leading edges or pulled in</span>\n",
    "<span class=\"comment\">% -0.5 for ending edges)</span>\n",
    "\n",
    "<span class=\"comment\">%Find double counted walls</span>\n",
    "intersect_Y = intersect(lead_idx_Y,end_idx_Y);\n",
    "intersect_X = intersect(lead_idx_X,end_idx_X);\n",
    "<span class=\"comment\">%Y</span>\n",
    "intersect_idx_mask_Y= ismember([X(:), Z(:)],[X(intersect_Y),Z(intersect_Y)],<span class=\"string\">'rows'</span>);\n",
    "self_Y = ismember([X(:), Y, Z(:)],[X(intersect_Y),Y(intersect_Y),Z(intersect_Y)],<span class=\"string\">'rows'</span>);\n",
    "intersect_idx_Y = find(intersect_idx_mask_Y &amp;not(self_Y));\n",
    "\n",
    "<span class=\"comment\">%X</span>\n",
    "intersect_idx_mask_X= ismember([Y(:), Z(:)],[Y(intersect_X),Z(intersect_X)],<span class=\"string\">'rows'</span>);\n",
    "self_X = ismember([X, Y, Z],[X(intersect_X),Y(intersect_X),Z(intersect_X)],<span class=\"string\">'rows'</span>);\n",
    "intersect_idx_X = find(intersect_idx_mask_X &amp;not(self_X));\n",
    "\n",
    "\n",
    "\n",
    "<span class=\"keyword\">try</span> <span class=\"comment\">%if something is strange with the grid, skip file</span>\n",
    "<span class=\"comment\">%compare by Z - X,Y</span>\n",
    "base1_Y = [X(intersect_idx_Y),Y(intersect_idx_Y),Z(intersect_idx_Y),intersect_Y];\n",
    "test1_Y = [X(intersect_Y),Y(intersect_Y),Z(intersect_Y),intersect_Y];\n",
    "base1_X = [X(intersect_idx_X),Y(intersect_idx_X),Z(intersect_idx_X),intersect_X];\n",
    "test1_X = [X(intersect_X),Y(intersect_X),Z(intersect_X),intersect_X];\n",
    "\n",
    "<span class=\"comment\">% Testing shifts - Y,X: Apply expected adjustments to the coordinates of</span>\n",
    "<span class=\"comment\">% the identified edges. Below will be the checking portion, based on</span>\n",
    "<span class=\"comment\">% changes of width of the building.</span>\n",
    "lead_test1_Y = [X(intersect_Y),Y(intersect_Y)+0.5,Z(intersect_Y),intersect_Y];\n",
    "end_test1_Y  =  [X(intersect_Y),Y(intersect_Y)-0.5,Z(intersect_Y),intersect_Y];\n",
    "lead_test1_X = [X(intersect_X)+0.5,Y(intersect_X),Z(intersect_X),intersect_X];\n",
    "end_test1_X =  [X(intersect_X)-0.5,Y(intersect_X),Z(intersect_X),intersect_X];\n",
    "\n",
    "<span class=\"comment\">%compute base widths - Y,X: Below we will consider original widths of the</span>\n",
    "<span class=\"comment\">%building to get a characteristic width to either accept or reject possible</span>\n",
    "<span class=\"comment\">%adjustments to the edges previously identified by the script. Details are</span>\n",
    "<span class=\"comment\">%below:</span>\n",
    "base_Y = sortrows(base1_Y,4);\n",
    "test_Y = sortrows(test1_Y,4);\n",
    "lead_test_Y = sortrows(lead_test1_Y,4);\n",
    "end_test_Y = sortrows(end_test1_Y,4);\n",
    "width_orig_Y = abs(base_Y(:,2)- test_Y(:,2));<span class=\"comment\">%lead is + 0.5</span>\n",
    "width_lead_Y = abs(base_Y(:,2)- lead_test_Y(:,2)); <span class=\"comment\">% end is  -0.5</span>\n",
    "width_end_Y = abs(base_Y(:,2)- end_test_Y(:,2));\n",
    "\n",
    "base_X = sortrows(base1_X,4);\n",
    "test_X = sortrows(test1_X,4);\n",
    "lead_test_X = sortrows(lead_test1_X,4);\n",
    "end_test_X = sortrows(end_test1_X,4);\n",
    "width_orig_X = abs(base_X(:,1)- test_X(:,1));<span class=\"comment\">%lead is + 0.5</span>\n",
    "width_lead_X = abs(base_X(:,1)- lead_test_X(:,1)) ;<span class=\"comment\">% end is  -0.5</span>\n",
    "width_end_X = abs(base_X(:,1)- end_test_X(:,1));\n",
    "\n",
    "\n",
    "<span class=\"comment\">%width gets larger for given leading/end edge means that the case</span>\n",
    "<span class=\"comment\">%identified by the script is incorrect, since the goal is to pull all edges</span>\n",
    "<span class=\"comment\">%in towards the center, so all adjustments should result in a smaller</span>\n",
    "<span class=\"comment\">%width. Any adjustment that is identified as increasing the width of the</span>\n",
    "<span class=\"comment\">%building is removed from the set and not applied.</span>\n",
    "remove_lead_Y = intersect_Y(find(width_lead_Y &gt; width_orig_Y));\n",
    "remove_end_Y = intersect_Y(find(width_end_Y &gt; width_orig_Y));\n",
    "lead_idx_Y = setdiff(lead_idx_Y,remove_lead_Y );\n",
    "end_idx_Y = setdiff(end_idx_Y,remove_end_Y );\n",
    "\n",
    "remove_lead_X = intersect_X(find(width_lead_X &gt; width_orig_X));\n",
    "remove_end_X = intersect_X(find(width_end_X &gt; width_orig_X));\n",
    "lead_idx_X = setdiff(lead_idx_X,remove_lead_X );\n",
    "end_idx_X = setdiff(end_idx_X,remove_end_X );\n",
    "\n",
    "<span class=\"keyword\">catch</span>\n",
    "        disp(<span class=\"string\">'concat error.'</span>)\n",
    "        skipped_file_count = skipped_file_count+1;\n",
    "        skipped_files = {skipped_files filename};\n",
    "        <span class=\"keyword\">continue</span>\n",
    "<span class=\"keyword\">end</span>\n",
    "\n",
    "<span class=\"comment\">% check intersections using same method outlined above. If the same</span>\n",
    "<span class=\"comment\">% coordinate can be reached by shifing two planes, it is on a corner, and</span>\n",
    "<span class=\"comment\">% should be removed.</span>\n",
    "X_shifted_up = [X(lead_idx_X)+0.5,Y(lead_idx_X),Z(lead_idx_X)];\n",
    "X_shifted_down = [X(end_idx_X)-0.5,Y(end_idx_X),Z(end_idx_X)];\n",
    "\n",
    "Y_shifted_up = [X(lead_idx_Y),Y(lead_idx_Y)+0.5,Z(lead_idx_Y)];\n",
    "Y_shifted_down = [X(end_idx_Y),Y(end_idx_Y)-0.5,Z(end_idx_Y)];\n",
    "\n",
    "Z_shifted_up = [X(lead_idx_Z),Y(lead_idx_Z),Z(lead_idx_Z)+0.5];\n",
    "Z_shifted_down = [X(end_idx_Z),Y(end_idx_Z),Z(end_idx_Z)-0.5];\n",
    "\n",
    "<span class=\"comment\">% Store coordinates of identified corners</span>\n",
    "X_shifted = [X_shifted_up;X_shifted_down];\n",
    "Y_shifted = [Y_shifted_up;Y_shifted_down];\n",
    "Z_shifted = [Z_shifted_up;Z_shifted_down];\n",
    "\n",
    "\n",
    "[cornersXY, cornersXYidx]= intersect(X_shifted, Y_shifted, <span class=\"string\">'rows'</span>);\n",
    "[cornersXZ,cornersXZidx]= intersect(X_shifted, Z_shifted, <span class=\"string\">'rows'</span>);\n",
    "[cornersYZ, cornersYZidx] = intersect(Y_shifted, Z_shifted, <span class=\"string\">'rows'</span>);\n",
    "\n",
    "ignore_arr_val = [cornersXY ;cornersXZ; cornersYZ];\n",
    "\n",
    "<span class=\"comment\">%Copy array</span>\n",
    "copy_X = X;\n",
    "copy_Y = Y;\n",
    "copy_Z = Z;\n",
    "\n",
    "<span class=\"comment\">%fixed edges</span>\n",
    "copy_X(lead_idx_X) = X(lead_idx_X)+0.5;\n",
    "copy_X(end_idx_X) = X(end_idx_X)-0.5;\n",
    "copy_Y(lead_idx_Y) = Y(lead_idx_Y)+0.5;\n",
    "copy_Y(end_idx_Y) = Y(end_idx_Y)-0.5;\n",
    "copy_Z(lead_idx_Z) = Z(lead_idx_Z)+0.5;\n",
    "copy_Z(end_idx_Z) = Z(end_idx_Z)-0.5;\n",
    "</pre><h2 id=\"5\">Map Coordinates to Indices (in 3d matrix)</h2><pre class=\"codeinput\">mat = zeros(51,51,51); <span class=\"comment\">% X-input  (51,51, 51) -&gt; values  0/1 (binary)</span>\n",
    "y_rad = zeros(51,51,51); <span class=\"comment\">% y-output(51,51,51)  -&gt; radiation values</span>\n",
    "\n",
    "building_X = round(copy_X+15-0.5)+1;\n",
    "building_Y = round(copy_Y+15-0.5)+1;\n",
    "building_Z = round(copy_Z+0.5)+1;\n",
    "building_radiation = b.rad;\n",
    "\n",
    "ignore_X = round(ignore_arr_val(:,1)+15-0.5)+1;\n",
    "ignore_Y = round(ignore_arr_val(:,2)+15-0.5)+1;\n",
    "ignore_Z = round(ignore_arr_val(:,3)+0.5)+1;\n",
    "\n",
    "xx = [building_X, building_Y, building_X];\n",
    "corners = [ignore_X ignore_Y ignore_Z];\n",
    "</pre><h2 id=\"6\">Populate X and y pre-processed matrix</h2><pre class=\"codeinput\"><span class=\"keyword\">for</span> idx_building = 1:length(xx)\n",
    "    mat(building_X(idx_building),building_Y(idx_building), building_Z(idx_building))  = 1;\n",
    "    y_rad(building_X(idx_building),building_Y(idx_building), building_Z(idx_building)) = building_radiation(idx_building);\n",
    "    <span class=\"keyword\">if</span> building_Z(idx_building) == 0\n",
    "        y_rad(building_X(idx_building),building_Y(idx_building), building_Z(idx_building)) = 0;\n",
    "    <span class=\"keyword\">end</span>\n",
    "\n",
    "<span class=\"keyword\">end</span>\n",
    "\n",
    "\n",
    "X_input = imfill(mat, <span class=\"string\">'holes'</span>);\n",
    "\n",
    "<span class=\"comment\">%Remove Previously identified edges voxels, since they have multiple</span>\n",
    "<span class=\"comment\">%radiation values and should not be considered by the network</span>\n",
    "<span class=\"keyword\">for</span> idx_corners = 1:length(corners)\n",
    "    X_input(ignore_X(idx_corners),ignore_Y(idx_corners), ignore_Z(idx_corners))  = 0;\n",
    "    y_rad(ignore_X(idx_corners),ignore_Y(idx_corners), ignore_Z(idx_corners))  = 0;\n",
    "<span class=\"keyword\">end</span>\n",
    "\n",
    "\n",
    "\n",
    "<span class=\"comment\">%Superimpose with boundary buildings so both are represented in same</span>\n",
    "<span class=\"comment\">%binary 3d matrix</span>\n",
    "X_input = X_input + boundaries;\n",
    "</pre><h2 id=\"7\">Plot Output</h2><p>Plot to look at output binary matrix</p><pre class=\"codeinput\">s = [51,51,51]; <span class=\"comment\">%size</span>\n",
    "A_idx = find(X_input==1);\n",
    "[I,J,K] = ind2sub(s,A_idx);\n",
    "figure\n",
    "scatter3(I,J,K,10,y_rad(A_idx))\n",
    "title(filename)\n",
    "</pre><h2 id=\"8\">Save .mat file - Export X and y preprocessed data</h2><pre class=\"codeinput\">savefile = [<span class=\"string\">'preprocessed_output_combined_with_boundary/'</span> filename(1:end-4) <span class=\"string\">'.mat'</span>];\n",
    "save(savefile, <span class=\"string\">'X_input'</span>, <span class=\"string\">'y_rad'</span>)\n",
    "</pre><pre class=\"codeinput\"><span class=\"keyword\">end</span>\n",
    "</pre><p class=\"footer\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORM MAT FILE TO NUMPY FOR MODEL INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET ALL FILES THAT ENDS WITH .MAT EXTENSION\n",
    "FILEPATH = 'preprocessed_output_combined_with_boundary/'\n",
    "files = [[]]*type_n\n",
    "folder_name = ['original','option2','rot']\n",
    "type_name = ['THREE BUILDING', 'SINGLE BUILDING', 'ROTATION']\n",
    "\n",
    "file_n_total = 0\n",
    "\n",
    "for i in range(type_n):\n",
    "    files[i] = [file for file in glob.glob(FILEPATH + folder_name[i]+\"/*.mat\")]\n",
    "    print (\"NUMBER OF FILES FOR DATA TYPE 0 (\"+type_name[i]+\"): \", len(files[0]))\n",
    "    file_n_total += len(files[i])\n",
    "\n",
    "print (\"NUMBER OF TOTAL FILES: \", file_n_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKES ABOUT 15 SECONDS.\n",
    "X, Y = [], []\n",
    "for i, file in enumerate(files):\n",
    "    cnt, total = 0, len(file)\n",
    "    x, y = [], []\n",
    "    for item in file:\n",
    "        cnt += 1\n",
    "        print (\"PROGRESS TYPE \"+str(i)+\": \"+ str(round(cnt / total * 100, 2))+ \"%\", end='\\r')\n",
    "        mat = scipy.io.loadmat(item)\n",
    "        x.append(mat['X_input'])\n",
    "        y.append(mat['y_rad'])\n",
    "    \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    \n",
    "    print('')\n",
    "    print (X[i].shape)\n",
    "    print (Y[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SANITY CHECKS\n",
    "print (\"[Input X]\\nMin:\" , np.concatenate(X, axis=0).min(), \"Max:\", np.concatenate(X, axis=0).max())\n",
    "print ()\n",
    "print (\"[Input y]\\nMin:\" , np.concatenate(Y, axis=0).min(), \"Max:\", np.concatenate(Y, axis=0).max())\n",
    "print ()\n",
    "print ('INPUT UNIQUE (SHOULD BE [0,1]): ', np.unique(np.concatenate(X, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_norm = 1500\n",
    "for i in range(type_n):\n",
    "    Y[i] = Y[i]/Y_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forceAxisEqual(ax, X, Y, Z):\n",
    "    max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max() / 2.0\n",
    "\n",
    "    mid_x = (X.max()+X.min()) * 0.5\n",
    "    mid_y = (Y.max()+Y.min()) * 0.5\n",
    "    mid_z = (Z.max()+Z.min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(0, max_range*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBuilding(x,y):\n",
    "    building = []\n",
    "    radiation = []\n",
    "    color = {0: 'blue', 1:'red'}\n",
    "\n",
    "    boundary = scipy.io.loadmat('combined_boundary.mat')\n",
    "    boundary = boundary['boundary_building_mat']\n",
    "\n",
    "    for i in range(0, 51):\n",
    "        for j in range(0, 51):\n",
    "            for k in range(0, 51):\n",
    "                if x[i][j][k] > 0:\n",
    "                    building.append([i,j,k,boundary[i][j][k]])\n",
    "                    if y[i,j,k]!=0:\n",
    "                        radiation.append([i,j,k,y[i][j][k]])\n",
    "\n",
    "    dfBuilding = pd.DataFrame(data=building)  \n",
    "    dfBuilding[3] = dfBuilding[3].apply(lambda x: color[int(x)])\n",
    "    dfRadiation = pd.DataFrame(data=radiation)  \n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax0 = fig.add_subplot(121, projection='3d')\n",
    "    ax0.scatter(dfBuilding[0], dfBuilding[1], dfBuilding[2], s=2, color=dfBuilding[3])\n",
    "    ax0.set_xlabel('X axis')\n",
    "    ax0.set_ylabel('Y axis')\n",
    "    ax0.set_zlabel('Z axis')\n",
    "    forceAxisEqual(ax0,dfBuilding[0], dfBuilding[1], dfBuilding[2])\n",
    "    ax0.set_title('Building Architecture (blue for target building, red for surronding building)')\n",
    "    \n",
    "    ax1 = fig.add_subplot(122, projection='3d')\n",
    "    im = ax1.scatter(dfRadiation[0], dfRadiation[1], dfRadiation[2], \n",
    "                     s=20, c=dfRadiation[3], cmap='hot', edgecolors='grey',vmin=0, vmax=1)\n",
    "    ax1.set_xlabel('X axis')\n",
    "    ax1.set_ylabel('Y axis')\n",
    "    ax1.set_zlabel('Z axis')\n",
    "    forceAxisEqual(ax1,dfRadiation[0], dfRadiation[1], dfRadiation[2])\n",
    "    ax1.set_title('Radiation Intensity (normalized)')\n",
    "    plt.colorbar(im)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt_idx = files[0].index('preprocessed_output_combined_with_boundary/original/9,27,21.mat') # np.random.randint(len(X)) # CHANGE THIS TO SEE WHICH FILE YOU WANT TO VISUALIZE\n",
    "plotBuilding(X[0][plt_idx], Y[0][plt_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = [[]]*type_n, [[]]*type_n, [[]]*type_n, [[]]*type_n\n",
    "\n",
    "for i in range(type_n):\n",
    "    X[i] = np.expand_dims(X[i], axis=-1)\n",
    "    Y[i] = np.expand_dims(Y[i], axis=-1)\n",
    "    X_train[i], X_val[i], Y_train[i], Y_val[i] = train_test_split(X[i], Y[i], test_size=0.2, random_state=99)\n",
    "    \n",
    "X_train_total = np.concatenate(X_train, axis=0)\n",
    "Y_train_total = np.concatenate(Y_train, axis=0)\n",
    "X_val_total = np.concatenate(X_val, axis=0)\n",
    "Y_val_total = np.concatenate(Y_val, axis=0)\n",
    "print(X_train_total.shape, X_val_total.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcFuvahzv54D"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Input, Reshape, Lambda, Concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Permute, Cropping2D\n",
    "from keras.layers import Conv3D, Deconvolution3D, MaxPooling3D, UpSampling3D, ZeroPadding3D, Cropping3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "The goal of the project is to predict the radiation intensity on buildins. Thus, the output of the network is a numerical value and we would like to use the MSE as the loss function.\n",
    "However, the simulation to generate the dataset can only get the radiation intensity at the surface of buildings. We then define a customized loss function to only account for the MSE loss at the surface of buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RadiationLoss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the loss for the radiation matrix.\n",
    "    \n",
    "    Inputs:\n",
    "    - y_true: radiation of the target building. 3D Tensor with radiation value at taget surface and others 0.\n",
    "    - y_pred: the prediction of the radiation.\n",
    "    \n",
    "    Returns:\n",
    "    - scalar mse loss, only calculated where radiation value not equal to zero\n",
    "    \"\"\"\n",
    "    \n",
    "    y_loc = K.cast(K.not_equal(y_true,K.constant(0)),'float')\n",
    "    return K.sum(K.pow(y_true-y_pred*y_loc,2))/K.sum(y_loc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "  When we build the neural network, we refer to the literature, *VoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition* (Maturana et al., 2015). **Voxnet** is 3D CNN that can be applied to create fast and accurate object class detectors for 3D point cloud data. We value the literature because the architecture of Voxnet is simple, and our dataset is also similar to point cloud (0/1 in the space).\n",
    "  In order to increase the range of captured information, i.e. to handle the shadow issue, we increase the depth of Voxnet. We also apply an autoencoder structure to map the latent variables back to 3D space, where our radiation results lie in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_size = (51, 51, 51, 1)\n",
    "\n",
    "inp = Input(matrix_size)\n",
    "\n",
    "# Voxnet structure + autoencoder\n",
    "enc = Conv3D(32, kernel_size=5, strides=2, padding='same', activation='relu')(inp)\n",
    "enc = Conv3D(32, kernel_size=3, strides=1, padding='same', activation='relu')(enc)\n",
    "enc = MaxPooling3D((2,2,2))(enc)\n",
    "\n",
    "enc = Conv3D(64, kernel_size=5, strides=2, padding='same', activation='relu')(enc)\n",
    "enc = Conv3D(64, kernel_size=3, strides=1, padding='same', activation='relu')(enc)\n",
    "enc = MaxPooling3D((2,2,2))(enc)\n",
    "conv_shape = enc.get_shape().as_list()\n",
    "\n",
    "enc = Flatten()(enc)\n",
    "latent = Dense(256, activation='relu')(enc)\n",
    "\n",
    "dec = Dense(np.prod(conv_shape[1:]), activation='relu')(latent)\n",
    "dec = Reshape(conv_shape[1:])(dec)\n",
    "\n",
    "dec = UpSampling3D((2,2,2))(dec)\n",
    "dec = Deconvolution3D(64, kernel_size=3, strides=1, padding='same', activation='relu')(dec)\n",
    "dec = Deconvolution3D(64, kernel_size=5, strides=2, padding='same', activation='relu')(dec)\n",
    "\n",
    "dec = UpSampling3D((2,2,2))(dec)\n",
    "dec = Deconvolution3D(32, kernel_size=3, strides=1, padding='valid', activation='relu')(dec)\n",
    "dec = Deconvolution3D(32, kernel_size=5, strides=2, padding='same', activation='relu')(dec)\n",
    "dec = Cropping3D(((0,1),(0,1),(0,1)))(dec)\n",
    "\n",
    "out = Conv3D(1, kernel_size=3, strides=1, padding='same', activation='sigmoid')(dec) # Assume normalized data [0,1]\n",
    "\n",
    "voxnet_model = Model(inp, out)\n",
    "voxnet_model.compile(optimizer='adam',loss=RadiationLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = voxnet_model.fit(X_train_total, Y_train_total, epochs=10, validation_data=(X_val_total, Y_val_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxnet_model.save_weights('voxnet2.w')\n",
    "# voxnet_model.load_weights('voxnet2.w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Representation View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxnet_model.load_weights('voxnet2.w')\n",
    "\n",
    "inp = Input(matrix_size)\n",
    "# Voxnet structure + autoencoder\n",
    "enc = Conv3D(32, kernel_size=5, strides=2, padding='same', activation='relu')(inp)\n",
    "enc = Conv3D(32, kernel_size=3, strides=1, padding='same', activation='relu')(enc)\n",
    "enc = MaxPooling3D((2,2,2))(enc)\n",
    "\n",
    "FirstLayer = Model(inp, enc)\n",
    "FirstLayer.summary()\n",
    "\n",
    "\n",
    "def plotRadiationLatent(y_true,y_pred,CHANNEL, CHANNEL_AVG, dim):\n",
    "    r_true = []\n",
    "    r_pred = []\n",
    "    currMax = np.max(y_pred)\n",
    "    for i in range(0, dim):\n",
    "        for j in range(0, dim):\n",
    "            for k in range(0, dim):\n",
    "                val = y_pred[i][j][k][CHANNEL]/currMax if not CHANNEL_AVG else np.average(y_pred[i][j][k])/currMax\n",
    "                if val > 0.1:\n",
    "                    r_pred.append([i,j,k, val])\n",
    "\n",
    "    for i in range(0, 51):\n",
    "        for j in range(0, 51):\n",
    "            for k in range(0, 51):\n",
    "                if y_true[i][j][k] != 0:\n",
    "                    r_true.append([i,j,k,y_true[i][j][k]])\n",
    "    \n",
    "    dfTrue = pd.DataFrame(data=r_true)                  \n",
    "    dfPred = pd.DataFrame(data=r_pred)  \n",
    "    \n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    \n",
    "    ax0 = fig.add_subplot(131, projection='3d')\n",
    "    im = ax0.scatter(dfTrue[0], dfTrue[1], dfTrue[2], \n",
    "                     s=20, c=dfTrue[3], cmap='hot', edgecolors='grey',vmin=0, vmax=1)\n",
    "    ax0.set_xlabel('X axis')\n",
    "    ax0.set_ylabel('Y axis')\n",
    "    ax0.set_zlabel('Z axis')\n",
    "    forceAxisEqual(ax0,dfTrue[0], dfTrue[1], dfTrue[2])\n",
    "    ax0.set_title('y_true')\n",
    "    plt.colorbar(im)\n",
    "    \n",
    "    ax1 = fig.add_subplot(132, projection='3d')\n",
    "    im = ax1.scatter(dfPred[0], dfPred[1], dfPred[2], \n",
    "                     s=20, c=dfPred[3], cmap='hot', edgecolors='grey',vmin=0, vmax=1)\n",
    "    ax1.set_xlabel('X axis')\n",
    "    ax1.set_ylabel('Y axis')\n",
    "    ax1.set_zlabel('Z axis')\n",
    "    forceAxisEqual(ax1,dfPred[0], dfPred[1], dfPred[2])\n",
    "    ax1.set_title('y_pred')\n",
    "    plt.colorbar(im) \n",
    "    plt.show()\n",
    "\n",
    "weight_list = voxnet_model.get_weights()\n",
    "for i in range(len(FirstLayer.layers)):\n",
    "    FirstLayer.layers[i].set_weight = weight_list[i]  \n",
    "    \n",
    "plt_idx = [87]\n",
    "CHANNEL = 5\n",
    "AVERAGE_CHANNEL = False\n",
    "dim = 13\n",
    "for i in plt_idx:\n",
    "    if AVERAGE_CHANNEL:\n",
    "        pred = FirstLayer.predict(np.expand_dims(X_val_total[i],axis=0))[0]\n",
    "        plotRadiationLatent(Y_val_total[i], pred, c, True, dim)\n",
    "    else:\n",
    "        for c in range(30,32):\n",
    "            pred = FirstLayer.predict(np.expand_dims(X_val_total[i],axis=0))[0]\n",
    "            plotRadiationLatent(Y_val_total[i], pred, c, True, dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "We can see that both training loss and validation loss decrease to around 3e-4 of mse after 10 epochs, i.e. 0.02 error on average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRadiation(y_true,y_pred):\n",
    "    r_true = []\n",
    "    r_pred = []\n",
    "\n",
    "    for i in range(0, 51):\n",
    "        for j in range(0, 51):\n",
    "            for k in range(0, 51):\n",
    "                if y_true[i][j][k] != 0:\n",
    "                    r_true.append([i,j,k,y_true[i][j][k]])\n",
    "                    r_pred.append([i,j,k,y_pred[i][j][k]])\n",
    "\n",
    "    dfTrue = pd.DataFrame(data=r_true)  \n",
    "    dfPred = pd.DataFrame(data=r_pred)  \n",
    "\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    ax0 = fig.add_subplot(131, projection='3d')\n",
    "    im = ax0.scatter(dfTrue[0], dfTrue[1], dfTrue[2], \n",
    "                     s=20, c=dfTrue[3], cmap='hot', edgecolors='grey',vmin=0, vmax=1)\n",
    "    ax0.set_xlabel('X axis')\n",
    "    ax0.set_ylabel('Y axis')\n",
    "    ax0.set_zlabel('Z axis')\n",
    "    forceAxisEqual(ax0,dfTrue[0], dfTrue[1], dfTrue[2])\n",
    "    ax0.set_title('y_true')\n",
    "    plt.colorbar(im)\n",
    "    \n",
    "    ax1 = fig.add_subplot(132, projection='3d')\n",
    "    im = ax1.scatter(dfPred[0], dfPred[1], dfPred[2], \n",
    "                     s=20, c=dfPred[3], cmap='hot', edgecolors='grey',vmin=0, vmax=1)\n",
    "    ax1.set_xlabel('X axis')\n",
    "    ax1.set_ylabel('Y axis')\n",
    "    ax1.set_zlabel('Z axis')\n",
    "    forceAxisEqual(ax1,dfPred[0], dfPred[1], dfPred[2])\n",
    "    ax1.set_title('y_pred')\n",
    "    plt.colorbar(im)\n",
    "    \n",
    "    ax2 = fig.add_subplot(133, projection='3d')\n",
    "    error = dfPred[3]-dfTrue[3]\n",
    "    e_range = np.max(abs(error))\n",
    "    im = ax2.scatter(dfPred[0], dfPred[1], dfPred[2], \n",
    "                     s=20, c=error, cmap='RdBu', edgecolors='grey',vmin=-e_range, vmax=e_range)\n",
    "    ax2.set_xlabel('X axis')\n",
    "    ax2.set_ylabel('Y axis')\n",
    "    ax2.set_zlabel('Z axis')\n",
    "    forceAxisEqual(ax2,dfPred[0], dfPred[1], dfPred[2])\n",
    "    ax2.set_title('error (y_pred-y_true)')\n",
    "    plt.colorbar(im)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt_idx = [[251, 172],[81, 11],[4, 7]]\n",
    "for i in range(type_n):\n",
    "    print(type_name[i])\n",
    "#     plt_idx[i] = np.random.randint(len(Y_val[i]), size=2)\n",
    "    for j in plt_idx[i]:\n",
    "        plotRadiation(Y_val[i][j], voxnet_model.predict(np.expand_dims(X_val[i][j],axis=0))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we visualize each building to have a closer look at the prediction, we found overall the prediction is quite accurate, but there is high error in some data at the boundary between the three buildings (e.g. around `y=30` and `x=21`), even when the neibouring buildings are at the same height. We can then tell that the neural network learns some specific rules about the boundary between the buildings based on the training data, but not the actual physics about the radiation intensity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of Scope Test Set\n",
    "\n",
    "In order to further investigate how our model is doing, we also test our model on a complete different architecture. We also include the data with and without surronding buildings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST 3 <img src=\"imgs/test3.PNG\" height=\"256\" width=\"256\" />\n",
    "TEST 4 <img src=\"imgs/test4.PNG\" height=\"256\" width=\"256\" />\n",
    "TEST 7 <img src=\"imgs/test7.PNG\" height=\"256\" width=\"256\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET ALL FILES THAT ENDS WITH .MAT EXTENSION\n",
    "FILEPATH = 'pre_processed_test'\n",
    "files = [file for file in glob.glob(FILEPATH + \"/*.mat\")]\n",
    "print (\"NUMBER OF FILES IN RESULT FOLDER: \", len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKES ABOUT 15 SECONDS.\n",
    "X_test, Y_test = [], []\n",
    "cnt, total = 0, len(files)\n",
    "for item in files:\n",
    "    cnt += 1\n",
    "    print (\"PROGRESS: \", round(cnt / total * 100, 2), \"%\")\n",
    "    clear_output(wait=True)\n",
    "    mat = scipy.io.loadmat(item)\n",
    "    X_test.append(mat['X_input'])\n",
    "    Y_test.append(mat['y_rad'])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "print (X_test.shape)\n",
    "print (Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SANITY CHECKS\n",
    "print (\"[Input X]\\nMin:\" , X_test.min(), \"Max:\", X_test.max())\n",
    "print ()\n",
    "print (\"[Input y]\\nMin:\" , Y_test.min(), \"Max:\", Y_test.max())\n",
    "print ()\n",
    "print ('INPUT UNIQUE (SHOULD BE [0,1]): ', np.unique(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test/Y_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_test)):\n",
    "    print(files[i])\n",
    "    plotBuilding(X_test[i], Y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(X_test,axis=-1)\n",
    "Y_test = np.expand_dims(Y_test,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y_test)):\n",
    "    print(files[i])\n",
    "    plotRadiation(Y_test[i], voxnet_model.predict(np.expand_dims(X_test[i],axis=0))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the predictionis very inaccurate. The model is trained to specific geometry. However, one good thing our model learn is that the surronding buildings have a negative effect on the radiation of the roof. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate Model\n",
    "\n",
    "We also look into the literature, *3D Convolutional Neural Networks for Tumor Segmentation using Long-range 2D Context* (Mlynarski et al., 2018). The model have the benefit of extracting long-range information using 2D model and combining them in a 3D model. We refer the literature and build a corresponding model, but the model have ~13M parameters with lots of submodel, which cause JupyterHub ResourceExhaustedError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractChannel(inp, i):\n",
    "    # Input 2D image with K channel. extract i-th channel\n",
    "    return K.expand_dims(inp[:,:, i])\n",
    "\n",
    "def sqeezeChannel(inp):\n",
    "    return K.squeeze(inp,axis=-1)\n",
    "\n",
    "def expandChannel(inp):\n",
    "    return K.expand_dims(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_size = (51, 51, 51, 1)\n",
    "last_channel = 30\n",
    "\n",
    "# 2D network\n",
    "def sub2Dnetwork_1c():\n",
    "    inp_2D = Input((matrix_size[0], matrix_size[1], 1))\n",
    "\n",
    "    x = Conv2D(32, padding='same', kernel_size=3)(inp_2D)\n",
    "    x = Conv2D(32, padding='same', kernel_size=3)(x)\n",
    "    x = MaxPooling2D((4,4))(x)\n",
    "    x = Conv2D(64, padding='same', kernel_size=3)(x)\n",
    "    x = Conv2D(32, padding='same', kernel_size=3)(x)\n",
    "    x = UpSampling2D((4,4))(x)\n",
    "    x = ZeroPadding2D(((1,2),(1,2)))(x)\n",
    "    x = Conv2D(32, padding='same', kernel_size=3)(x)\n",
    "    out = Conv2D(last_channel, padding='same', kernel_size=3)(x)\n",
    "\n",
    "    return  Model(inp_2D, out)\n",
    "\n",
    "def sub2Dnetwork_51c():\n",
    "    inp_2D = Input((matrix_size[:-1]))\n",
    "\n",
    "    x = Conv2D(32, padding='same', kernel_size=3)(inp_2D)\n",
    "    x = Conv2D(32, padding='same', kernel_size=3)(x)\n",
    "    x = MaxPooling2D((4,4))(x)\n",
    "    x = Conv2D(64, padding='same', kernel_size=3)(x)\n",
    "    x = Conv2D(32, padding='same', kernel_size=3)(x)\n",
    "    x = UpSampling2D((4,4))(x)\n",
    "    x = ZeroPadding2D(((1,2),(1,2)))(x)\n",
    "    x = Conv2D(32, padding='same', kernel_size=3)(x)\n",
    "    out = Conv2D(last_channel, padding='same', kernel_size=3)(x)\n",
    "\n",
    "    return  Model(inp_2D, out)\n",
    "\n",
    "def combine2Dnetwork():\n",
    "    inp_2D = Input((matrix_size[0], matrix_size[1], last_channel*(matrix_size[2]+1)))\n",
    "    x = Conv2D(32, padding='same', kernel_size=3)(inp_2D)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(64, padding='same', kernel_size=3)(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(128, padding='same', kernel_size=3)(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    x = Conv2D(64, padding='same', kernel_size=3)(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    x = ZeroPadding2D(((1,2),(1,2)))(x)\n",
    "    x = Conv2D(32, padding='same', kernel_size=3)(x)\n",
    "    out = Conv2D(matrix_size[2], padding='same', kernel_size=3)(x)\n",
    "\n",
    "    return Model(inp_2D, out)\n",
    "\n",
    "def get2Dnetwork():\n",
    "    inp = Input(matrix_size[:-1])\n",
    "    subnetworks = []\n",
    "    suboutputs = []\n",
    "    for i in range(matrix_size[-2]):\n",
    "        subnet = sub2Dnetwork_1c()\n",
    "        subout = subnet(Lambda(lambda x: extractChannel(x, i))(inp))\n",
    "        suboutputs.append(subout)\n",
    "        subnetworks.append(subnet)\n",
    "    subnet = sub2Dnetwork_51c()\n",
    "    subout = subnet(inp)\n",
    "    suboutputs.append(subout)\n",
    "    subnetworks.append(subnet)\n",
    "\n",
    "    inp_combined = Concatenate()(suboutputs)\n",
    "    comb = combine2Dnetwork()\n",
    "    return Model(inp,comb(inp_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D network\n",
    "inp = Input(matrix_size)\n",
    "inp_2D = Lambda(sqeezeChannel)(inp)\n",
    "\n",
    "X_model = get2Dnetwork()\n",
    "Y_model = get2Dnetwork()\n",
    "Z_model = get2Dnetwork()\n",
    "\n",
    "inp_2D_X = Permute((1,2,3))(inp_2D)\n",
    "inp_2D_Y = Permute((1,3,2))(inp_2D)\n",
    "inp_2D_Z = Permute((2,3,1))(inp_2D)\n",
    "\n",
    "out_2D_X = X_model(inp_2D_X)\n",
    "out_2D_Y = Y_model(inp_2D_Y)\n",
    "out_2D_Z = Z_model(inp_2D_Z)\n",
    "\n",
    "inp_3D = Concatenate()([inp,\n",
    "                        Lambda(expandChannel)(out_2D_X),\n",
    "                        Lambda(expandChannel)(out_2D_Y),\n",
    "                        Lambda(expandChannel)(out_2D_Z)])\n",
    "\n",
    "enc = Conv3D(32, kernel_size=3, strides=1, padding='same', activation='relu')(inp_3D)\n",
    "enc = Conv3D(32, kernel_size=3, strides=1, padding='same', activation='relu')(enc)\n",
    "enc = MaxPooling3D((2,2,2))(enc)\n",
    "\n",
    "enc = Conv3D(64, kernel_size=3, strides=1, padding='same', activation='relu')(enc)\n",
    "enc = Conv3D(64, kernel_size=3, strides=1, padding='same', activation='relu')(enc)\n",
    "enc = MaxPooling3D((2,2,2))(enc)\n",
    "\n",
    "enc = Conv3D(128, kernel_size=3, strides=1, padding='same', activation='relu')(enc)\n",
    "enc = Conv3D(128, kernel_size=3, strides=1, padding='same', activation='relu')(enc)\n",
    "dec = UpSampling3D((2,2,2))(enc)\n",
    "\n",
    "dec = Conv3D(64, kernel_size=3, strides=1, padding='same', activation='relu')(dec)\n",
    "dec = Conv3D(64, kernel_size=3, strides=1, padding='same', activation='relu')(dec)\n",
    "dec = UpSampling3D((2,2,2))(dec)\n",
    "dec = ZeroPadding3D(((1,2),(1,2),(1,2)))(dec) # pad 0s at one side to match the size\n",
    "\n",
    "dec = Conv3D(32, kernel_size=3, strides=1, padding='same', activation='relu')(dec)\n",
    "dec = Conv3D(32, kernel_size=3, strides=1, padding='same', activation='relu')(dec)\n",
    "\n",
    "out = Conv3D(1, kernel_size=3, strides=1, padding='same', activation='sigmoid')(dec) # Assume normalized data [0,1]\n",
    "\n",
    "lr2D_model = Model(inp, out)\n",
    "lr2D_model.compile(optimizer='adam',loss=RadiationLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2D_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lr2D_model.fit(X_train, Y_train, epochs=10, validation_data=(X_test, Y_test)) # ResourceExhaustedError"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
